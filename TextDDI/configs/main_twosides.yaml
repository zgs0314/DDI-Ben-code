max_length: 256
num_labels: 209
model_type: 'twosides_cls'
dataset: 'twosides' #
pretrained_model_path: './pretrained_model_path/roberta-base' #
info_dict_path: 'data/twosides/twosides_sents.json'
annotation: 'twosides_finetune-roberta-large'
drug_name_only: False
use_zero_shot: True
use_id : False
drug_only_max_length: 256
not_random : False
checkpoint : './checkpoints/06-12/twosides-old-name-only/checkpoint_epoch4.pt' # TODO
resume: False
use_gpu: True
multi_gpu: False
deepspeed: False
gpuid: '1'
gpu_num: 1
eval: False
test: True
filemode: 'w'
patience : 5
num_train_epochs: 200
max_train_steps: 0
per_gpu_train_batch_size: 4
gradient_accumulation_steps: 8
eval_batch_size: 32
log_step: 10
lr_scheduler_type: 'constant' # constant cosine
fp16: False
lr: 1.0e-5
weight_decay: 1.0e-6  # 1.0e-6 #1e-2
epsilon: 1.0e-8
vocab_size: 50257
seed: 2